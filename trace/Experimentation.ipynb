{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOV = 115\n",
    "OUTPT = 151\n",
    "INPT = OUTPT + FOV - 1\n",
    "\n",
    "\n",
    "map_0 = 1\n",
    "\n",
    "# Layer 1: Diluted Convolution\n",
    "field_1 = 4\n",
    "stride_1 = 1\n",
    "dilation_1 = 1\n",
    "map_1 = 48\n",
    "\n",
    "image = tf.placeholder(tf.float32, shape=[1, 95, 95, 1])\n",
    "# Shape: [# layers per batch, patch size, patch size, labels per pixel]\n",
    "target = tf.placeholder(tf.float32, shape=[None, None, None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([field_1, field_1, map_0, map_1], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[map_1]))\n",
    "conv1 = tf.nn.convolution(image, W_conv1, strides=[stride_1, stride_1], padding='VALID',\n",
    "                          dilation_rate=[dilation_1, dilation_1])\n",
    "h_conv1 = tf.nn.relu(conv1 + b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 1, 48)\n",
      "(48,)\n",
      "(1, 92, 92, 48)\n",
      "(1, 92, 92, 48)\n"
     ]
    }
   ],
   "source": [
    "print(W_conv1.get_shape())\n",
    "print(b_conv1.get_shape())\n",
    "print(conv1.get_shape())\n",
    "print(h_conv1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "field_2 = 2\n",
    "stride_2 = 1\n",
    "dilation_2 = 1\n",
    "h_pool1 = tf.nn.pool(h_conv1, window_shape=[field_2, field_2], dilation_rate=[dilation_2, dilation_2],\n",
    "                             strides=[stride_2, stride_2], padding='VALID', pooling_type='MAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 91, 91, 48)\n"
     ]
    }
   ],
   "source": [
    "print(h_pool1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  \"\"\"\n",
    "  One should generally initialize weights with a small amount of noise\n",
    "  for symmetry breaking, and to prevent 0 gradients.\n",
    "  Since we're using ReLU neurons, it is also good practice to initialize\n",
    "  them with a slightly positive initial bias to avoid \"dead neurons\".\n",
    "  \"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W, dilation=None):\n",
    "  return tf.nn.convolution(x, W, strides=[1, 1], padding='VALID', dilation_rate=[dilation, dilation])\n",
    "\n",
    "\n",
    "def max_pool(x, dilation=None, strides=[2, 2], window_shape=[2, 2]):\n",
    "  return tf.nn.pool(x, window_shape=window_shape, dilation_rate= [dilation, dilation],\n",
    "                       strides=strides, padding='VALID', pooling_type='MAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOV = 95\n",
    "OUTPT = 101\n",
    "INPT = FOV + 2 * (OUTPT//2)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'm1': 48,\n",
    "    'm2': 48,\n",
    "    'm3': 48,\n",
    "    'm4': 48,\n",
    "    'fc': 200,\n",
    "    'lr': 0.001,\n",
    "    'out': 101\n",
    "}\n",
    "\n",
    "map_1 = params['m1']\n",
    "map_2 = params['m2']\n",
    "map_3 = params['m3']\n",
    "map_4 = params['m4']\n",
    "fc = params['fc']\n",
    "        \n",
    "image = tf.placeholder(tf.float32, shape=[1, INPT, INPT, 1])\n",
    "target = tf.placeholder(tf.float32, shape=[1, OUTPT, OUTPT, 2])\n",
    "\n",
    "# layer 1 - original stride 1\n",
    "W_conv1 = weight_variable([4, 4, 1, map_1])\n",
    "b_conv1 = bias_variable([map_1])\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1, dilation=1) + b_conv1)\n",
    "\n",
    "# layer 2 - original stride 2\n",
    "h_pool1 = max_pool(h_conv1, strides=[1, 1], dilation=1)\n",
    "\n",
    "# layer 3 - original stride 1\n",
    "W_conv2 = weight_variable([5, 5, map_1, map_2])\n",
    "b_conv2 = bias_variable([map_2])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, dilation=2) + b_conv2)\n",
    "\n",
    "# layer 4 - original stride 2\n",
    "h_pool2 = max_pool(h_conv2, strides=[1, 1], dilation=2)\n",
    "\n",
    "# layer 5 - original stride 1\n",
    "W_conv3 = weight_variable([4, 4, map_2, map_3])\n",
    "b_conv3 = bias_variable([map_3])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, dilation=4) + b_conv3)\n",
    "\n",
    "# layer 6 - original stride 2\n",
    "h_pool3 = max_pool(h_conv3, strides=[1, 1], dilation=4)\n",
    "\n",
    "# layer 7 - original stride 1\n",
    "W_conv4 = weight_variable([4, 4, map_3, map_4])\n",
    "b_conv4 = bias_variable([map_4])\n",
    "h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4, dilation=8) + b_conv4)\n",
    "\n",
    "# layer 8 - original stride 2\n",
    "h_pool4 = max_pool(h_conv4, strides=[1, 1], dilation=8)\n",
    "\n",
    "# layer 9 - original stride 1\n",
    "W_fc1 = weight_variable([3, 3, map_4, fc])\n",
    "b_fc1 = bias_variable([fc])\n",
    "h_fc1 = tf.nn.relu(conv2d(h_pool4, W_fc1, dilation=16) + b_fc1)\n",
    "\n",
    "# layer 10 - original stride 2\n",
    "W_fc2 = weight_variable([1, 1, fc, 2])\n",
    "b_fc2 = bias_variable([1])\n",
    "prediction = conv2d(h_fc1, W_fc2, dilation=16) + b_fc2\n",
    "\n",
    "s_pred = tf.nn.sigmoid(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n",
      "(1, 192, 192, 48)\n",
      "L2\n",
      "(1, 191, 191, 48)\n",
      "L3\n",
      "(1, 183, 183, 48)\n",
      "L4\n",
      "(1, 181, 181, 48)\n",
      "L5\n",
      "(1, 169, 169, 48)\n",
      "L6\n",
      "(1, 165, 165, 48)\n",
      "L7\n",
      "(1, 141, 141, 48)\n",
      "L8\n",
      "(1, 133, 133, 48)\n",
      "L9\n",
      "(1, 101, 101, 200)\n",
      "L10\n",
      "(1, 101, 101, 2)\n",
      "Pred\n",
      "(1, 101, 101, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"L1\")\n",
    "print(h_conv1.get_shape())\n",
    "print(\"L2\")\n",
    "print(h_pool1.get_shape())\n",
    "print(\"L3\")\n",
    "print(h_conv2.get_shape())\n",
    "print(\"L4\")\n",
    "print(h_pool2.get_shape())\n",
    "print(\"L5\")\n",
    "print(h_conv3.get_shape())\n",
    "print(\"L6\")\n",
    "print(h_pool3.get_shape())\n",
    "print(\"L7\")\n",
    "print(h_conv4.get_shape())\n",
    "print(\"L8\")\n",
    "print(h_pool4.get_shape())\n",
    "print(\"L9\")\n",
    "print(h_fc1.get_shape())\n",
    "print(\"L10\")\n",
    "print(prediction.get_shape())\n",
    "print(\"Pred\")\n",
    "print(s_pred.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models.conv_net as cnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Layer\n",
      "(1, 195, 195, 1)\n",
      "Layer 1,\ttype: conv2d,\tfilter: [4, 4],\tFOV: 4\n",
      "Layer 2,\ttype: pool,\tfilter: [2, 2],\tFOV: 5\n",
      "Layer 3,\ttype: conv2d,\tfilter: [5, 5],\tFOV: 13\n",
      "Layer 4,\ttype: pool,\tfilter: [2, 2],\tFOV: 15\n",
      "Layer 5,\ttype: conv2d,\tfilter: [4, 4],\tFOV: 27\n",
      "Layer 6,\ttype: pool,\tfilter: [2, 2],\tFOV: 31\n",
      "Layer 7,\ttype: conv2d,\tfilter: [4, 4],\tFOV: 55\n",
      "Layer 8,\ttype: pool,\tfilter: [2, 2],\tFOV: 63\n",
      "Layer 9,\ttype: conv2d,\tfilter: [3, 3],\tFOV: 95\n",
      "Layer 10,\ttype: conv2d,\tfilter: [1, 1],\tFOV: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.conv_net.ConvNet instance at 0x7f606d36c5f0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnet.ConvNet(cnet.DEFAULT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
